{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "51e58f64",
      "metadata": {
        "id": "51e58f64"
      },
      "source": [
        "ML4NLP3 -- Graph parser\n",
        "======"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10327515",
      "metadata": {
        "id": "10327515"
      },
      "source": [
        "In this exercise you are given a fully working natural language parser for English although minimalistic.\n",
        "As it stands it does not work very well for many reasons:\n",
        "\n",
        "* The parser structure is incomplete\n",
        "* The parser is unbatched\n",
        "* The parser does not contain evaluation code\n",
        "\n",
        "You task is to improve it until you get something decent.\n",
        "While doing so, you will learn how to build deeper neural networks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB-BOyP7iO1X",
        "outputId": "13bf4447-7a8f-4205-b1ac-d03ca0c5b2dc"
      },
      "id": "mB-BOyP7iO1X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.10.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.10.0 torchmetrics-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.functional.classification.f_beta import multiclass_fbeta_score, binary_fbeta_score\n",
        "import torch"
      ],
      "metadata": {
        "id": "ow7WP5yriaYU"
      },
      "id": "ow7WP5yriaYU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds  = torch.tensor([1, 0, 0, 1])\n",
        "target = torch.tensor([1, 1, 0, 0])\n",
        "ic(multiclass_fbeta_score(preds, target, beta=1.0, average='micro', num_classes=2))\n",
        "\n",
        "preds  = torch.tensor([1, 0, 0, 1])\n",
        "target = torch.tensor([1, 1, 0, 0])\n",
        "ic(binary_fbeta_score(preds, target, beta=1.0, threshold=0.5))\n",
        "\n",
        "\n",
        "\n",
        "d2preds  = torch.tensor([[0, 0, 0, 1],[0, 0, 0, 1]])\n",
        "d2target = torch.tensor([[1, 1, 0, 0],[1, 1, 0, 0]])\n",
        "ic(multiclass_fbeta_score(d2preds, d2target, beta=1.0, average='micro', num_classes=2))\n",
        "\n",
        "preds  = torch.tensor([0.0, 0.0, 0.0, 0.9])\n",
        "target = torch.tensor([1, 1, 0, 0])\n",
        "ic(binary_fbeta_score(preds, target, beta=1.0, threshold=0.5))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwkOeT4DiWOv",
        "outputId": "1e1663b8-3ca6-44d9-c266-2bd431c9de3e"
      },
      "id": "KwkOeT4DiWOv",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ic| multiclass_fbeta_score(preds, target, beta=1.0, average='micro', num_classes=2): tensor(0.5000)\n",
            "ic| binary_fbeta_score(preds, target, beta=1.0, threshold=0.5): tensor(0.5000)\n",
            "ic| multiclass_fbeta_score(d2preds, d2target, beta=1.0, average='micro', num_classes=2): tensor(0.2500)\n",
            "ic| binary_fbeta_score(preds, target, beta=1.0, threshold=0.5): tensor(0.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icecream\n",
        "from icecream import ic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP8sd2OfPVTQ",
        "outputId": "8819d40c-a89a-459e-d23a-e41583c1ccfa"
      },
      "id": "xP8sd2OfPVTQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Collecting colorama>=0.3.9 (from icecream)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.16.1)\n",
            "Collecting executing>=0.3.1 (from icecream)\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.0.1 (from icecream)\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.0.1 icecream-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa48b9c0",
      "metadata": {
        "id": "aa48b9c0"
      },
      "source": [
        "The conll parsing data\n",
        "---------------------\n",
        "\n",
        "You can download the parsing data by running the following block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e9251e",
      "metadata": {
        "id": "16e9251e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80db2b7c-2f8e-40e1-f541-3f8297d1f75a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('test.conllu', <http.client.HTTPMessage at 0x7e70c1604880>)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from urllib.request import urlretrieve\n",
        "\n",
        "urlretrieve('https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-train.conllu','train.conllu')\n",
        "urlretrieve('https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu','dev.conllu')\n",
        "urlretrieve('https://raw.githubusercontent.com/UniversalDependencies/UD_English-EWT/master/en_ewt-ud-dev.conllu','test.conllu')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f99cb613",
      "metadata": {
        "id": "f99cb613"
      },
      "source": [
        "*you* can observe the data to figure how it looks like, by running the following block:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d7c199",
      "metadata": {
        "id": "60d7c199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06080606-dbf0-4734-c3c4-565f9976b104"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# newdoc id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713\n",
            "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001\n",
            "# newpar id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-p0001\n",
            "# text = From the AP comes this story :\n",
            "1\tFrom\tfrom\tADP\tIN\t_\t3\tcase\t3:case\t_\n",
            "2\tthe\tthe\tDET\tDT\tDefinite=Def|PronType=Art\t3\tdet\t3:det\t_\n",
            "3\tAP\tAP\tPROPN\tNNP\tNumber=Sing\t4\tobl\t4:obl:from\t_\n",
            "4\tcomes\tcome\tVERB\tVBZ\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t0\troot\t0:root\t_\n",
            "5\tthis\tthis\tDET\tDT\tNumber=Sing|PronType=Dem\t6\tdet\t6:det\t_\n",
            "6\tstory\tstory\tNOUN\tNN\tNumber=Sing\t4\tnsubj\t4:nsubj\t_\n",
            "7\t:\t:\tPUNCT\t:\t_\t4\tpunct\t4:punct\t_\n",
            "\n",
            "# sent_id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0002\n",
            "# newpar id = weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-p0002\n",
            "# text = President Bush on Tuesday nominated two individuals to replace retiring jurists on federal courts in the Washington area.\n",
            "1\tPresident\tPresident\tPROPN\tNNP\tNumber=Sing\t5\tnsubj\t5:nsubj\t_\n",
            "2\tBush\tBush\tPROPN\tNNP\tNumber=Sing\t1\tflat\t1:flat\t_\n",
            "3\ton\ton\tADP\tIN\t_\t4\tcase\t4:case\t_\n",
            "4\tTuesday\tTuesday\tPROPN\tNNP\tNumber=Sing\t5\tobl\t5:obl:on\t_\n",
            "5\tnominated\tnominate\tVERB\tVBD\tMood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\t0\troot\t0:root\t_\n",
            "6\ttwo\ttwo\tNUM\tCD\tNumForm=Word|NumType=Card\t7\tnummod\t7:nummod\t_\n",
            "7\tindividuals\tindividual\tNOUN\tNNS\tNumber=Plur\t5\tobj\t5:obj\t_\n",
            "8\tto\tto\tPART\tTO\t_\t9\tmark\t9:mark\t_\n",
            "9\treplace\treplace\tVERB\tVB\tVerbForm=Inf\t5\tadvcl\t5:advcl:to\t_\n",
            "10\tretiring\tretire\tVERB\tVBG\tVerbForm=Ger\t11\tamod\t11:amod\t_\n",
            "11\tjurists\tjurist\tNOUN\tNNS\tNumber=Plur\t9\tobj\t9:obj\t_\n",
            "12\ton\ton\tADP\tIN\t_\t14\tcase\t14:case\t_\n"
          ]
        }
      ],
      "source": [
        "N  = 25 #prints the 25 first lines of the dev file\n",
        "idata = open('dev.conllu')\n",
        "for idx,line in enumerate(idata):\n",
        "    print(line.strip())\n",
        "    if idx > N:\n",
        "        break\n",
        "idata.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "255825fb",
      "metadata": {
        "id": "255825fb"
      },
      "source": [
        "Reading data and encoding it on tensors\n",
        "----------------------------\n",
        "\n",
        "\n",
        "The vocabulary class implements a vocabumary mapping strings to integers and vice-versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac27a692",
      "metadata": {
        "id": "ac27a692"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "    This is a class mapping symbols to integers and vice-versa\n",
        "    \"\"\"\n",
        "    def __init__(self,symbols=None):\n",
        "\n",
        "        self.symb2idx = {}\n",
        "        self.idx2sym  = []\n",
        "        if symbols:\n",
        "            self.update(symbols)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2sym)\n",
        "\n",
        "\n",
        "    def update(self,symbol_list):\n",
        "        \"\"\"\n",
        "        Adds new symbols to the vocabulary if not already in\n",
        "        \"\"\"\n",
        "        for S in symbol_list:\n",
        "            if S not in self.symb2idx:\n",
        "                self.symb2idx[S] = len(self.idx2sym)\n",
        "                self.idx2sym.append(S)\n",
        "\n",
        "    def rev_lookup(self, idx):\n",
        "        \"\"\"\n",
        "        This is a reverse lookup. Given an integer returns the string\n",
        "        \"\"\"\n",
        "        return self.idx2sym[idx]\n",
        "\n",
        "\n",
        "    def __call__(self,symbol,fallback=None):\n",
        "        \"\"\"\n",
        "        This is an alias for the lookup method\n",
        "\n",
        "        Symbol lookup in a vocabulary. Given a symbol returns the int code.\n",
        "        fallback is a string used to return an ID when the symbol is unknown to the vocabulary\n",
        "        \"\"\"\n",
        "        return self.lookup(symbol,fallback)\n",
        "\n",
        "\n",
        "    def lookup(self,symbol,fallback=None):\n",
        "        \"\"\"\n",
        "        Symbol lookup in a vocabulary. Given a symbol returns the int code.\n",
        "        fallback is a string used to return an ID when the symbol is unknown to the vocabulary\n",
        "\n",
        "        \"\"\"\n",
        "        if fallback:\n",
        "            return self.symb2idx.get(symbol,self.symb2idx[fallback])\n",
        "        else:\n",
        "            return self.symb2idx[symbol]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5adb431",
      "metadata": {
        "id": "a5adb431"
      },
      "source": [
        "The Conll Reader\n",
        "--------------------\n",
        "\n",
        "The ConllReader reads the data files and generates an enumeration of graph representations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d63eea",
      "metadata": {
        "id": "28d63eea"
      },
      "outputs": [],
      "source": [
        "class ConllReader:\n",
        "\n",
        "    CONLL_FIELDS = (\"tokidx\", \"token\", \"low_token\",\"upos\",\"pos\",\"features\",\"head\",\"deplabel\")\n",
        "\n",
        "    def __init__(self,node_attr=(\"token\",\"upos\"),store_vocab=(\"token\",\"upos\",\"deplabel\")):\n",
        "            self.node_attr    = list(node_attr)\n",
        "            if \"tokidx\" not in node_attr:\n",
        "                self.node_attr.append(\"tokidx\")\n",
        "\n",
        "            self.stored_vocab = {}\n",
        "            if store_vocab is not None:\n",
        "                self.stored_vocab = {elt: [] for elt in store_vocab}\n",
        "\n",
        "\n",
        "    def get_vocabulary(self,conll_field):\n",
        "        \"\"\"\n",
        "        Returns the set of symbols for the conll field with name in one of:\n",
        "\n",
        "        * token\n",
        "        * low_token\n",
        "        * pos\n",
        "        * upos\n",
        "        * deplabel\n",
        "\n",
        "        \"\"\"\n",
        "        return list(set(self.stored_vocab[conll_field]))\n",
        "\n",
        "    def __call__(self,filename):\n",
        "        return self.readfile(filename)\n",
        "\n",
        "\n",
        "    def readfile(self,filename):\n",
        "\n",
        "        istream = open(filename)\n",
        "\n",
        "        sent_struct = {}\n",
        "        for line in istream:\n",
        "            line         = line.strip()\n",
        "            if line and line[0] != \"#\":\n",
        "                #print(line)\n",
        "                tokidx, token,low_token,upos,pos,features,headidx,deplabel,extended, _ =  line.split()\n",
        "                features = dict(zip(ConllReader.CONLL_FIELDS,(tokidx, token,low_token,upos,pos,features,headidx,deplabel)))\n",
        "\n",
        "                if not any(c in [\"-\",\".\"] for c in tokidx): #skips multi word annotation\n",
        "\n",
        "                    #extract_edges and nodes\n",
        "                    edges = sent_struct.get(\"edges\",[])\n",
        "                    if extended != \"_\":  # conll extended case (creating graph structure)\n",
        "                        govlist = extended.replace(\" \",\"\").split(\"|\")\n",
        "                        for gov_chunk in govlist:\n",
        "                            headidx, deplabel = gov_chunk.split(\":\")[:2]\n",
        "                            try:\n",
        "                                edges.append( {\"src\":int(headidx),\"dst\":int(tokidx),\"elbl\":deplabel})\n",
        "                            except ValueError:\n",
        "                                pass\n",
        "                    else:\n",
        "                        tokidx, headidx = int(tokidx), int(headidx)\n",
        "                        edges.append( {\"src\":headidx,\"dst\":tokidx,\"elbl\":deplabel} )\n",
        "\n",
        "                    sent_struct[\"edges\"] = edges\n",
        "                    nodes = sent_struct.get(\"nodes\",[])\n",
        "                    nodes.append( {F:features[F] if F != \"tokidx\" else int(features[F]) for F in self.node_attr})\n",
        "                    sent_struct[\"nodes\"] = nodes\n",
        "\n",
        "                    #update vocabulary if needed\n",
        "                    for key, value in self.stored_vocab.items():\n",
        "                        self.stored_vocab[key].append(features[key])\n",
        "\n",
        "            elif sent_struct:\n",
        "                yield sent_struct\n",
        "                sent_struct = {}\n",
        "\n",
        "        if sent_struct:\n",
        "            yield sent_struct\n",
        "        istream.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a34818e9",
      "metadata": {
        "id": "a34818e9"
      },
      "source": [
        "This cell exemplifies the usage of the ConllReader together with the Vocabulary class. It outputs a string representation of a graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e4b700",
      "metadata": {
        "id": "58e4b700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ab14784-f3ff-4817-d293-ef9ddfd8d167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'edges': [{'src': 3, 'dst': 1, 'elbl': 'case'}, {'src': 3, 'dst': 2, 'elbl': 'det'}, {'src': 4, 'dst': 3, 'elbl': 'obl'}, {'src': 0, 'dst': 4, 'elbl': 'root'}, {'src': 6, 'dst': 5, 'elbl': 'det'}, {'src': 4, 'dst': 6, 'elbl': 'nsubj'}, {'src': 4, 'dst': 7, 'elbl': 'punct'}], 'nodes': [{'token': 'From', 'upos': 'ADP', 'tokidx': 1}, {'token': 'the', 'upos': 'DET', 'tokidx': 2}, {'token': 'AP', 'upos': 'PROPN', 'tokidx': 3}, {'token': 'comes', 'upos': 'VERB', 'tokidx': 4}, {'token': 'this', 'upos': 'DET', 'tokidx': 5}, {'token': 'story', 'upos': 'NOUN', 'tokidx': 6}, {'token': ':', 'upos': 'PUNCT', 'tokidx': 7}]}\n"
          ]
        }
      ],
      "source": [
        "conll_reader = ConllReader()\n",
        "corpus = list(conll_reader('dev.conllu'))\n",
        "print(corpus[0])                                        #prints out the first graph of the dev set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "682f881f",
      "metadata": {
        "id": "682f881f"
      },
      "source": [
        "Dataset and DataLoader\n",
        "-----------------------\n",
        "\n",
        "This class implements a pytorch Dataset for the parsing problem.\n",
        "The Dataset stores a full list of graphs and the DataLoader is the class used to provide tensors to the neural network.\n",
        "[See also the pytorch documentation](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
        "\n",
        "Here the DataLoader is the main class of interest.\n",
        "To get a dataloader, one first creates a dataset and then calls the ``get_loader`` method of the data set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c3aea7",
      "metadata": {
        "id": "85c3aea7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "class ConllDataset(Dataset):\n",
        "        \"\"\"\n",
        "        This class turns a conll into a dataset.\n",
        "        It also provides a dataloader for training and predicting from this dataset\n",
        "        \"\"\"\n",
        "        def __init__(self, vocabulary, filename):\n",
        "\n",
        "            super(ConllDataset, self).__init__()\n",
        "            self.data = []\n",
        "            self.vocabulary = vocabulary\n",
        "            conll_reader = ConllReader()\n",
        "            self.data = list(conll_reader(filename))[:100]\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.data)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            src_idxes  = torch.tensor([edge[\"src\"] for edge in self.data[idx][\"edges\"]])\n",
        "            tgt_idxes  = torch.tensor([edge[\"dst\"] for edge in self.data[idx][\"edges\"]])\n",
        "            tokens_ids = torch.tensor([self.vocabulary.lookup(\"[ROOT]\")]+[self.vocabulary.lookup(node[\"token\"],\"[UNK]\") for node in self.data[idx][\"nodes\"]])\n",
        "            return (src_idxes,tgt_idxes,tokens_ids)\n",
        "\n",
        "        def get_loader(self, batch_size=1, num_workers=4):\n",
        "            return DataLoader(self, batch_size=batch_size, num_workers=num_workers, collate_fn=None,shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5420cdb9",
      "metadata": {
        "id": "5420cdb9"
      },
      "source": [
        "The Parsing model\n",
        "-----------\n",
        "\n",
        "The parsing model uses an auxiliary class that computes bilinear scores.\n",
        "Given a words embedding matrix it computes a weighted adjacency matrix (the parsing graph).\n",
        "In this exercise, we typically provide the same matrix to the forward function of this module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588c1710",
      "metadata": {
        "id": "588c1710"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Bilinear(nn.Module):\n",
        "\n",
        "    def __init__(self,emb_size):\n",
        "        super(Bilinear, self).__init__()\n",
        "        self.W = nn.Parameter(torch.empty(emb_size,emb_size))\n",
        "        nn.init.xavier_normal_(self.W)\n",
        "\n",
        "    def forward(self,src_embedding,tgt_embedding):\n",
        "        return src_embedding @ self.W @ tgt_embedding.transpose(-1,-2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2134c826",
      "metadata": {
        "id": "2134c826"
      },
      "source": [
        "The parsing model will also include a FeedForwardNetwork auxiliary module to include below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25033f8f",
      "metadata": {
        "id": "25033f8f"
      },
      "outputs": [],
      "source": [
        "#Feed Forward Network\n",
        "\n",
        "#<HERE>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eda0e445",
      "metadata": {
        "id": "eda0e445"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "from tqdm.notebook import tqdm #progress bar\n",
        "\n",
        "class GraphParser(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,vocabulary,emb_size):\n",
        "\n",
        "        super(GraphParser, self).__init__()\n",
        "        self.E          = nn.Embedding(len(vocabulary),emb_size)\n",
        "        self.bilinear   = Bilinear(emb_size)\n",
        "\n",
        "\n",
        "    def forward(self,tok_IDs):\n",
        "        \"\"\"\n",
        "        Given token IDs, returns the predicted adjacency matrix\n",
        "        \"\"\"\n",
        "\n",
        "        #Basic parsing\n",
        "        X = self.E(tok_IDs)\n",
        "        adjacency = self.bilinear(X, X)\n",
        "        return adjacency\n",
        "\n",
        "\n",
        "    def predict(self,predloader):\n",
        "        \"\"\"\n",
        "        Generates graphs in a prediction context\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for (src_idx,tgt_idx,tok_IDs) in tqdm(predloader):\n",
        "                src_idx      = src_idx.squeeze()\n",
        "                tgt_idx      = tgt_idx.squeeze()\n",
        "                tok_IDs      = tok_IDs.squeeze()\n",
        "                predicted    = self.forward(tok_IDs)\n",
        "                predicted    = predicted  > 0.\n",
        "                yield (torch.nonzero(predicted),tok_IDs)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self,trainloader,epochs):\n",
        "\n",
        "        optimizer = optim.Adam(self.parameters(),lr=0.001)\n",
        "        loss_fnc   = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        #computes the gold adjacency matrix from sparse idxes\n",
        "        def adjacency_fnc(src_idx,tgt_idx,seq_len):\n",
        "            A = torch.zeros(seq_len,seq_len)\n",
        "            A[src_idx,tgt_idx] = 1.\n",
        "            return A\n",
        "\n",
        "\n",
        "        for e in range(epochs):\n",
        "\n",
        "            loss_lst = []\n",
        "\n",
        "            for (src_idx,tgt_idx,tok_IDs) in tqdm(trainloader):\n",
        "                optimizer.zero_grad()\n",
        "                src_idx      = src_idx.squeeze() #we currently work in unbatched mode\n",
        "                tgt_idx      = tgt_idx.squeeze()\n",
        "                tok_IDs      = tok_IDs.squeeze()\n",
        "                predicted    = self.forward(tok_IDs)\n",
        "                loss = loss_fnc(predicted,adjacency_fnc(src_idx,tgt_idx,len(tok_IDs)))\n",
        "                loss.backward()\n",
        "                loss_lst.append(loss.item())\n",
        "                optimizer.step()\n",
        "\n",
        "            print(\"Epoch\",e,\" Loss\",sum(loss_lst))\n",
        "\n",
        "\n",
        "####\n",
        "#Turns a graph back to a Conll string.\n",
        "def graph2conll(token_vocabulary,src,tgt,tok_IDs):\n",
        "        \"\"\"\n",
        "        Outputs a conll from the parser output\n",
        "        \"\"\"\n",
        "        tokens  = [token_vocabulary.rev_lookup(tokid) for tokid in tok_IDs]\n",
        "        src,tgt = src.tolist(),tgt.tolist()\n",
        "        edges   = [(src,tgt) for src,tgt in zip(src,tgt)]\n",
        "\n",
        "        print(\"src\",src)\n",
        "        print(\"tgt\",tgt)\n",
        "\n",
        "        num_nodes = len(tok_IDs)\n",
        "        result = [ [] for _ in range(num_nodes) ]\n",
        "        for govid,depid in edges:\n",
        "            result[depid].append( (depid,'none',govid) )\n",
        "\n",
        "        #make_str\n",
        "        for idx,elt in enumerate(result):\n",
        "            if len(elt) == 0: #creates a dummy root link for unconnected nodes\n",
        "                result[idx] = \"\\t\".join([str(idx),str(tokens[idx]),\"_\",\"_\",\"_\",\"_\",\"0\",'root',\"_\",\"_\"])\n",
        "            else:\n",
        "               dep,lbl,gov = elt[0]\n",
        "               enhanced    = '|'.join([\"%d:%s\"%(gov,lbl)  for (dep,lbl,gov) in elt])\n",
        "               result[idx] = (\"\\t\".join([str(dep), str(tokens[idx]), \"_\", \"_\", \"_\", \"_\", str(gov), lbl, enhanced, \"_\"]))\n",
        "        result[0] = \"# text = \"+' '.join(tokens[1:])\n",
        "        return \"\\n\".join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8be74746",
      "metadata": {
        "scrolled": true,
        "id": "8be74746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579,
          "referenced_widgets": [
            "f2514a895eb24e28960e7dafd25b8364",
            "eacffaa42c174465a89309e877ab75f3",
            "4ae88763c64249eba0c101c87899d3c6",
            "c3c6d6b0b6df4dcea30408cf4b453218",
            "3da0f6e41f51421db7712b71dcffa263",
            "53b92699a89d4cdc84a796877b39adf6",
            "c03a8ef2a7534be1b48dc2cf4ec73d7a",
            "b643d42bdeb548a4995b566828af6d14",
            "ee65402dfc964ef58f7ca74138fdc288",
            "1976796e18a44249996464bc844b56b6",
            "9136e1a080d04be4b16f22dffebabea9",
            "d887ffaf02994a0699fe74ffd468002d",
            "5f5adbbd5f94455982a26c8156ede658",
            "4c6c3bc6005848f0bb8963aacef825be",
            "dbc08145cc0947cc8bc121b3e01565cd",
            "4ef6a504fddd46188c85d50975473c2b",
            "a782d5a92e32400c8099af8939c51c8e",
            "b54b0e48fb8145738dbab845d9f24db6",
            "637c6c52f8e243fbbc1b54ff77ebbce7",
            "5bf212000be44befb2a928c7db9032bc",
            "f195ae63bccc4f96941087026ab4c44e",
            "7ee094f9232840eb8a17dfa4d66d3b02"
          ]
        },
        "outputId": "28012f30-5fda-42ec-dd21-c64ff47e98cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2514a895eb24e28960e7dafd25b8364"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0  Loss 678.7554614543915\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d887ffaf02994a0699fe74ffd468002d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-955f079651f6>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#predict and display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-7c61f0c57b3a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainloader, epochs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mloss_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" Loss\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m                             )\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 state_steps)\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    312\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#make vocabulary\n",
        "conll_reader = ConllReader()\n",
        "corpus = list(conll_reader('train.conllu'))\n",
        "vocab = Vocabulary(symbols = [\"[ROOT]\",\"[UNK]\"])\n",
        "vocab.update(list(conll_reader.get_vocabulary('token')))\n",
        "\n",
        "#make train & dev loader\n",
        "trainset = ConllDataset(vocab,'train.conllu').get_loader()\n",
        "devset   = ConllDataset(vocab,'dev.conllu').get_loader()\n",
        "#testset  = ConllDataset(vocab,'mini.conll').get_loader()\n",
        "\n",
        "#train model\n",
        "gp = GraphParser(vocab,512)\n",
        "# gp.train(devset,10)\n",
        "\n",
        "#predict and display\n",
        "for edges,tokens in gp.predict(devset):\n",
        "    src,tgt = edges.T[0],edges.T[1]\n",
        "\n",
        "    ic()\n",
        "    print(graph2conll(vocab,src,tgt,tokens))\n",
        "    print()\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(devset)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7y2td6lO0X9",
        "outputId": "08046dc9-425b-456c-9720-c92a77f88eb7"
      },
      "id": "j7y2td6lO0X9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 4,  4,  4,  0,  6,  4, 10,  9, 10,  4, 13, 13, 10, 17, 17, 17, 10, 23,\n",
            "         23, 23, 23, 23, 10, 17, 25, 23, 29, 29, 29,  4, 29,  4]]), tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
            "         19, 20, 21, 22, 23, 23, 24, 25, 26, 27, 28, 29, 30, 31]]), tensor([[    0,  2286, 19582,  5652,  1352, 15281, 12374,  6444, 17592,     1,\n",
            "           571, 16298, 17592,  7870,   324, 19153, 19403, 11359,  6444, 19403,\n",
            "          9251, 17592, 10136,  1106, 10502,   621,   324,  9259, 18881,  5688,\n",
            "         11598, 10731]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ba5a0fc",
      "metadata": {
        "id": "1ba5a0fc"
      },
      "source": [
        "Questions :\n",
        "-----------\n",
        "\n",
        "**For each question you have to write explictly where you added something in the code.\n",
        "Answers to questions 1 to 3 and 8 will get you 10/20. Answering to more questions increases the note.**\n",
        "\n",
        "**Besides code, adding comments and explanations to your answers  is required**\n",
        "\n",
        "\n",
        "\n",
        "1. Add the key missing components to this parser : an LSTM and two feed forward networks to specialize word embeddings for governors and dependant. To do that you will implement a FeedForward Module by yourself. See also poly or [(Dozat and Manning 2018)](https://aclanthology.org/P18-2077.pdf)\n",
        "2. Add a validation function to the parser. During training you should be able to report the loss on the training set and on the validation set.\n",
        "3. Add an evaluation metric to your validation function able to measure the F-score of your parser:\n",
        "$$F = \\frac{2 P R}{P+R}$$\n",
        "\n",
        "$$P = \\frac{numPredictedCorrect}{totalPredicted}$$\n",
        "\n",
        "$$R = \\frac{numPredictedCorrect}{totalCorrect}$$\n",
        "\n",
        "4. Explain how you manage unknown words. You may modify existing code to improve.\n",
        "5. Add code to predict edge labels\n",
        "6. Add code to perform batching. This requires to modify the `collate_fn` of the [DataLoader](https://pytorch.org/docs/stable/data.html) for padding\n",
        "7. Add and test anything you find useful to this parser (including materials from other exercises or other classes)\n",
        "8. Train and test your parser in order to get some decent results\n",
        "\n",
        "*Note. The training process run without batching will be slow. I advise that you set up your code by using a small data set such as the dev set (or even smaller). Use the full training set once everything is working well. The edge label prediction and the batching question are harder than the others*\n",
        "\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f2514a895eb24e28960e7dafd25b8364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eacffaa42c174465a89309e877ab75f3",
              "IPY_MODEL_4ae88763c64249eba0c101c87899d3c6",
              "IPY_MODEL_c3c6d6b0b6df4dcea30408cf4b453218"
            ],
            "layout": "IPY_MODEL_3da0f6e41f51421db7712b71dcffa263"
          }
        },
        "eacffaa42c174465a89309e877ab75f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b92699a89d4cdc84a796877b39adf6",
            "placeholder": "​",
            "style": "IPY_MODEL_c03a8ef2a7534be1b48dc2cf4ec73d7a",
            "value": "100%"
          }
        },
        "4ae88763c64249eba0c101c87899d3c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b643d42bdeb548a4995b566828af6d14",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee65402dfc964ef58f7ca74138fdc288",
            "value": 100
          }
        },
        "c3c6d6b0b6df4dcea30408cf4b453218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1976796e18a44249996464bc844b56b6",
            "placeholder": "​",
            "style": "IPY_MODEL_9136e1a080d04be4b16f22dffebabea9",
            "value": " 100/100 [00:20&lt;00:00,  4.75it/s]"
          }
        },
        "3da0f6e41f51421db7712b71dcffa263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b92699a89d4cdc84a796877b39adf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c03a8ef2a7534be1b48dc2cf4ec73d7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b643d42bdeb548a4995b566828af6d14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee65402dfc964ef58f7ca74138fdc288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1976796e18a44249996464bc844b56b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9136e1a080d04be4b16f22dffebabea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d887ffaf02994a0699fe74ffd468002d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f5adbbd5f94455982a26c8156ede658",
              "IPY_MODEL_4c6c3bc6005848f0bb8963aacef825be",
              "IPY_MODEL_dbc08145cc0947cc8bc121b3e01565cd"
            ],
            "layout": "IPY_MODEL_4ef6a504fddd46188c85d50975473c2b"
          }
        },
        "5f5adbbd5f94455982a26c8156ede658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a782d5a92e32400c8099af8939c51c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_b54b0e48fb8145738dbab845d9f24db6",
            "value": " 46%"
          }
        },
        "4c6c3bc6005848f0bb8963aacef825be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_637c6c52f8e243fbbc1b54ff77ebbce7",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bf212000be44befb2a928c7db9032bc",
            "value": 46
          }
        },
        "dbc08145cc0947cc8bc121b3e01565cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f195ae63bccc4f96941087026ab4c44e",
            "placeholder": "​",
            "style": "IPY_MODEL_7ee094f9232840eb8a17dfa4d66d3b02",
            "value": " 46/100 [00:09&lt;00:17,  3.10it/s]"
          }
        },
        "4ef6a504fddd46188c85d50975473c2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a782d5a92e32400c8099af8939c51c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b54b0e48fb8145738dbab845d9f24db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "637c6c52f8e243fbbc1b54ff77ebbce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf212000be44befb2a928c7db9032bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f195ae63bccc4f96941087026ab4c44e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee094f9232840eb8a17dfa4d66d3b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}