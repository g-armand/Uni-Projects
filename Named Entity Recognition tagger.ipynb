{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GgTLQvRT5t9L"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NkqtpB4hC_A"
      },
      "source": [
        "# M2 project : NER tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tzB0WgQhtH9"
      },
      "source": [
        "This project aims to implement a NER Tagger with Pytorch. We will be using the English CONLL 2003 data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIUnG00_hYl0"
      },
      "source": [
        "Data download & description\n",
        "--------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCe8as2ej9E0",
        "outputId": "d7546434-c665-45ce-f0f5-5e658c534df7"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.train','eng.train')\n",
        "urlretrieve('https://raw.githubusercontent.com/pranabsarkar/Conll_task/master/conll-2003/eng.testa','eng.testa')\n",
        "\n",
        "#Prints the beginning of the training set\n",
        "istream = open('eng.train')\n",
        "for idx, line in enumerate(istream):\n",
        "  print(line.strip())\n",
        "  if idx >=20:\n",
        "    break\n",
        "istream.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-DOCSTART- -X- -X- O\n",
            "\n",
            "EU NNP I-NP I-ORG\n",
            "rejects VBZ I-VP O\n",
            "German JJ I-NP I-MISC\n",
            "call NN I-NP O\n",
            "to TO I-VP O\n",
            "boycott VB I-VP O\n",
            "British JJ I-NP I-MISC\n",
            "lamb NN I-NP O\n",
            ". . O O\n",
            "\n",
            "Peter NNP I-NP I-PER\n",
            "Blackburn NNP I-NP I-PER\n",
            "\n",
            "BRUSSELS NNP I-NP I-LOC\n",
            "1996-08-22 CD I-NP O\n",
            "\n",
            "The DT I-NP O\n",
            "European NNP I-NP I-ORG\n",
            "Commission NNP I-NP I-ORG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2f9l5U7mjLz"
      },
      "source": [
        "The CONLL 2003 dataset encodes each token on a single line followed by its annotation. A token line is a quadruple:\n",
        "\n",
        "> (token,tag,chunk,named entity)\n",
        "\n",
        "A named entity tagger aims to predict the named entity annotations given the raw tokens. The NER tags follows the IOB convention.\n",
        "* **I** stands for **Inside** and is used to flag tokens that are part of a named entity.\n",
        "* **B** stands for **Begin** and is used to flag a token starting a new entity when the preceding token is already part of an entity.\n",
        "* **O** stands for **Outside** and is used to flag tokens that are not part of a named entity.\n",
        "\n",
        "The I and B Tag are followed by a specifier. For instance I-PER means that the named entity refers to a person, I-ORG means that the entity is refers to an Organisation.\n",
        "\n",
        "Sentences are separated by a blank line. The train file is `eng.train`, the dev file is `eng.testa`. I will evaluate your work with a test file unknown to you.\n",
        "To do this, I will change the content of the dev file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mUet-DlpMel"
      },
      "source": [
        "First exercise : data preprocessing (5pts)\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAo1csOSpgBh"
      },
      "source": [
        "Using CONLL2003 the train file, you will:\n",
        "\n",
        "* Extract an input vocabulary and create two maps: one mapping tokens to integers and a second mapping integers to tokens (see the pdf notes)\n",
        "* Include elements in the input vocabulary for padding and for unknown words\n",
        "* Extract an output vocabulary (the set of NER tags) and returns two maps\n",
        "mapping tags to integer and vice-versa.\n",
        "\n",
        "These functionalities should be implemented in a function with signature `vocabulary(filename)` that returns the two maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9r8XbqsH8u"
      },
      "source": [
        "def vocabulary(filename,input_vocab,padding='<pad>',unknown='<unk>'):\n",
        "    #input_vocab is a boolean flag that tells if we extract input or output vocabulary\n",
        "    #the two optional flags indicate that a padding and an unknown token\n",
        "    #have to be added to the vocabulary if their value is not None\n",
        "\n",
        "    idx2sym = {}\n",
        "    sym2idx = {}\n",
        "    current_index = 0\n",
        "\n",
        "    if padding is not None:\n",
        "        idx2sym[current_index] = padding\n",
        "        sym2idx[padding] = current_index\n",
        "        current_index += 1\n",
        "\n",
        "    if unknown is not None:\n",
        "        idx2sym[current_index] = unknown\n",
        "        sym2idx[unknown] = current_index\n",
        "        current_index += 1\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        lines = file.readlines()[1:]  # Read all lines except the first one: \"-DOCSTART- -X- -X- O\"\n",
        "\n",
        "    current_sentence = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            for token in current_sentence:\n",
        "                word = token[0]  # Token\n",
        "                tag = token[3]   # NER Tag\n",
        "                if input_vocab:\n",
        "                    if word not in sym2idx:\n",
        "                        idx2sym[current_index] = word\n",
        "                        sym2idx[word] = current_index\n",
        "                        current_index += 1\n",
        "                else:\n",
        "                    if tag not in sym2idx:\n",
        "                        idx2sym[current_index] = tag\n",
        "                        sym2idx[tag] = current_index\n",
        "                        current_index += 1\n",
        "            current_sentence = []\n",
        "        else:\n",
        "            parts = line.split()\n",
        "            current_sentence.append(parts)\n",
        "\n",
        "    return idx2sym, sym2idx\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M36kJLft0IO"
      },
      "source": [
        "Now we implement three functions:\n",
        "\n",
        "* One that performs padding\n",
        "* The second will encode a sequence of tokens (or a sequence of tags) on integers\n",
        "* The third will decode as sequence of symbols from integers to strings\n",
        "\n",
        "At test time, some tokens might not belong to the vocabulary. Ensure that your encoding function does not crash in this case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV98Rb66uRmz"
      },
      "source": [
        "def pad_sequence(sequence,pad_size,pad_token):\n",
        "    #returns a list with additional pad tokens if needed\n",
        "    if len(sequence) >= pad_size:\n",
        "        return sequence[:pad_size]\n",
        "    else:\n",
        "        return sequence + [pad_token] * (pad_size - len(sequence))\n",
        "\n",
        "def code_sequence(sequence,coding_map,unk_token=None):\n",
        "    #takes a list of strings and returns a list of integers\n",
        "    if unk_token is not None:\n",
        "        return [coding_map.get(token, coding_map[unk_token]) for token in sequence]\n",
        "    else:\n",
        "        return [coding_map[token] for token in sequence]\n",
        "\n",
        "def decode_sequence(sequence,decoding_map):\n",
        "    #takes a list of integers and returns a list of strings\n",
        "    return [decoding_map[idx] for idx in sequence]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj9pkrOv6-xS"
      },
      "source": [
        "Second exercise: data generator (5pts)\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJiBNu737Suv"
      },
      "source": [
        "In this second exercise, we will write a mini-batch generator.\n",
        "This is a class in charge of generating randomized batches of data from the dataset. We start by implementing two functions for reading the textfile\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP3mMhU58Lgu"
      },
      "source": [
        "def read_conll_tokens(conllfilename):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (tokens)\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "\n",
        "    with open(conllfilename, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if current_sentence:\n",
        "                    sentences.append(current_sentence)\n",
        "                current_sentence = []\n",
        "            else:\n",
        "                parts = line.split()\n",
        "                token = parts[0]\n",
        "                current_sentence.append(token)\n",
        "\n",
        "    return sentences\n",
        "\n",
        "def read_conll_tags(conllfilename):\n",
        "    \"\"\"\n",
        "    Reads a CONLL 2003 file and returns a list of sentences.\n",
        "    A sentence is a list of strings (NER-tags)\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    current_sentence = []\n",
        "\n",
        "    with open(conllfilename, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                if current_sentence:\n",
        "                    sentences.append(current_sentence)\n",
        "                current_sentence = []\n",
        "            else:\n",
        "                parts = line.split()\n",
        "                ner_tag = parts[-1]\n",
        "                current_sentence.append(ner_tag)\n",
        "\n",
        "    return sentences\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0QpXfMmQ0xz"
      },
      "source": [
        "\n",
        "\n",
        "Now we implement the class. You will rely on the helper functions designed above in order to fill in the blanks in the constructor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol2Hp2rcGNK9"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from random import shuffle\n",
        "\n",
        "class DataGenerator:\n",
        "\n",
        "        #Reuse all relevant helper functions defined above to solve the problems\n",
        "        def __init__(self,conllfilename, parentgenerator = None, pad_token='<pad>',unk_token='<unk>'):\n",
        "\n",
        "              if parentgenerator is not None: #Reuse the encodings of the parent if specified\n",
        "                  self.pad_token      = parentgenerator.pad_token\n",
        "                  self.unk_token      = parentgenerator.unk_token\n",
        "                  self.input_sym2idx  = parentgenerator.input_sym2idx\n",
        "                  self.input_idx2sym  = parentgenerator.input_idx2sym\n",
        "                  self.output_sym2idx = parentgenerator.output_sym2idx\n",
        "                  self.output_idx2sym = parentgenerator.output_idx2sym\n",
        "              else:                           #Creates new encodings\n",
        "                  self.pad_token = pad_token\n",
        "                  self.unk_token = unk_token\n",
        "                  # Create 4 encoding maps from datafile\n",
        "                  self.input_idx2sym,self.input_sym2idx   = vocabulary(conllfilename, True, self.pad_token, self.unk_token)\n",
        "                  self.output_idx2sym,self.output_sym2idx = vocabulary(conllfilename, False, self.pad_token, self.unk_token)\n",
        "\n",
        "\n",
        "              # store the conll dataset with sentence structure (a list of lists of strings) in the following fields\n",
        "              self.Xtokens = read_conll_tokens(conllfilename)\n",
        "              self.Ytokens = read_conll_tags(conllfilename)\n",
        "\n",
        "\n",
        "        def generate_batches(self,batch_size):\n",
        "\n",
        "              #This is an example generator function yielding one batch after another\n",
        "              #Batches are lists of lists\n",
        "\n",
        "              assert(len(self.Xtokens) == len(self.Ytokens))\n",
        "\n",
        "              N     = len(self.Xtokens)\n",
        "              idxes = list(range(N))\n",
        "\n",
        "              #Data ordering (try to explain why these 2 lines make sense...)\n",
        "              #  shuffling and sorting by sentence length are common techniques used to ensure randomness and efficiency when generating batches of data for training neural networks\n",
        "              shuffle(idxes)\n",
        "              idxes.sort(key=lambda idx: len(self.Xtokens[idx]))\n",
        "\n",
        "              #batch generation\n",
        "              bstart = 0\n",
        "              while bstart < N:\n",
        "                 bend        = min(bstart+batch_size,N)\n",
        "                 batch_idxes = idxes[bstart:bend]\n",
        "                 batch_len   = max(len(self.Xtokens[idx]) for idx in batch_idxes)\n",
        "\n",
        "                 seqX = [ pad_sequence(self.Xtokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqY = [ pad_sequence(self.Ytokens[idx],batch_len,self.pad_token) for idx in batch_idxes]\n",
        "                 seqX = [ code_sequence(seq,self.input_sym2idx,self.unk_token) for seq in seqX]\n",
        "                 seqY = [ code_sequence(seq,self.output_sym2idx) for seq in seqY]\n",
        "\n",
        "                 assert(len(seqX) == len(seqY))\n",
        "                 yield (seqX,seqY)\n",
        "                 bstart += batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = DataGenerator('eng.train')\n",
        "validset = DataGenerator('eng.testa',parentgenerator = trainset)"
      ],
      "metadata": {
        "id": "j-lfJ_SLrIO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpt98v1US9-t"
      },
      "source": [
        "Third exercise : implement the tagger (5pts)\n",
        "---------------\n",
        "This is the core exercise. There are three main tasks:\n",
        "* Implement parameter allocation. This implies allocating the embedding layer, the LSTM (or bi-LSTM) layer and the Linear Layer.\n",
        "* Implement the forward method. This method expects a tensor encoding the input and outputs a tensor of predictions\n",
        "* Implement the train method\n",
        "\n",
        "The evaluation (`validate`) method is given and cannot be modified. But it can be used as source of inspiration for implementing the train method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x6y33H2TKiQ"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "class NERtagger(nn.Module):\n",
        "\n",
        "      def __init__(self,traingenerator,embedding_size,hidden_size,dropout_proba,device='cpu'):\n",
        "        super(NERtagger, self).__init__()\n",
        "        self.embedding_size    = embedding_size\n",
        "        self.hidden_size       = hidden_size\n",
        "        self.allocate_params(traingenerator,device, dropout_proba)\n",
        "\n",
        "      def load(self,filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "\n",
        "      def allocate_params(self,datagenerator,device, dropout_proba):\n",
        "\n",
        "        vocab_size = len(datagenerator.input_sym2idx)\n",
        "        num_labels = len(datagenerator.output_sym2idx)\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, self.embedding_size)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
        "        self.linear = nn.Linear(self.hidden_size * 2, num_labels)  # Output size is doubled due to bidirectional LSTM\n",
        "        self.dropout = nn.Dropout(dropout_proba)\n",
        "        self.to(device)\n",
        "\n",
        "      def forward(self,Xinput):\n",
        "\n",
        "        embedded = self.embedding(Xinput)\n",
        "        lstm_output, _ = self.lstm(embedded)\n",
        "        lstm_output = self.dropout(lstm_output)\n",
        "        output = self.linear(lstm_output)\n",
        "\n",
        "        return output\n",
        "\n",
        "      def train(self,traingenerator,validgenerator,epochs,batch_size,device='cpu',learning_rate=0.001):\n",
        "\n",
        "        self.minloss = 10000000  # The minimum loss found so far on validation data\n",
        "\n",
        "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "        device = torch.device(device)\n",
        "        pad_index = traingenerator.output_sym2idx[traingenerator.pad_token]\n",
        "        loss_fnc = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            batch_losses = []\n",
        "\n",
        "            for (seqX, seqY) in traingenerator.generate_batches(batch_size):\n",
        "                X = torch.LongTensor(seqX).to(device)\n",
        "                Y = torch.LongTensor(seqY).to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                Yhat = self.forward(X)\n",
        "\n",
        "                # Flattening and loss computation\n",
        "                batch_size, seq_len = Y.shape\n",
        "                Yhat = Yhat.view(batch_size * seq_len, -1)\n",
        "                Y = Y.view(batch_size * seq_len)\n",
        "                loss = loss_fnc(Yhat, Y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                batch_losses.append(loss.item())\n",
        "\n",
        "            train_loss = sum(batch_losses) / len(batch_losses)\n",
        "\n",
        "            valid_loss, valid_accuracy = self.validate(validgenerator, batch_size, device)\n",
        "\n",
        "            print(f'Train Loss: {train_loss:.4f}\\n--- END OF EPOCH {epoch}')\n",
        "\n",
        "            # Save the model if the validation loss improves\n",
        "            if valid_loss < self.minloss:\n",
        "                self.minloss = valid_loss\n",
        "                torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "\n",
        "      def validate(self,datagenerator,batch_size,device='cpu',save_min_model=False):\n",
        "\n",
        "          batch_accurracies = []\n",
        "          batch_losses      = []\n",
        "\n",
        "          device = torch.device(device)\n",
        "          pad_index = datagenerator.output_sym2idx[datagenerator.pad_token]\n",
        "          loss_fnc  = nn.CrossEntropyLoss(ignore_index=pad_index)\n",
        "\n",
        "          for (seqX,seqY) in datagenerator.generate_batches(batch_size):\n",
        "                with torch.no_grad():\n",
        "                  X = torch.LongTensor(seqX).to(device)\n",
        "                  Y = torch.LongTensor(seqY).to(device)\n",
        "\n",
        "                  Yhat = self.forward(X)\n",
        "\n",
        "                  #Flattening and loss computation\n",
        "                  batch_size,seq_len = Y.shape\n",
        "                  Yhat = Yhat.view(batch_size*seq_len,-1)\n",
        "                  Y    = Y.view(batch_size*seq_len)\n",
        "                  loss = loss_fnc(Yhat,Y)\n",
        "                  batch_losses.append(loss.item())\n",
        "\n",
        "                  #Accurracy computation\n",
        "                  mask    = (Y != pad_index)\n",
        "                  Yargmax = torch.argmax(Yhat,dim=1)\n",
        "                  correct = torch.sum((Yargmax == Y) * mask)\n",
        "                  total   = torch.sum(mask)\n",
        "                  batch_accurracies.append(float(correct)/float(total))\n",
        "\n",
        "          L = len(batch_losses)\n",
        "          valid_loss = sum(batch_losses)/L\n",
        "\n",
        "          if save_min_model and valid_loss < self.minloss:\n",
        "            self.minloss = valid_loss\n",
        "            torch.save(self.state_dict(), 'tagger_params.pt')\n",
        "\n",
        "          print('[valid] mean Loss = %f | mean accurracy = %f'%(valid_loss,sum(batch_accurracies)/L))\n",
        "\n",
        "          return valid_loss, sum(batch_accurracies)/L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    model = NERtagger(trainset, 32, 64, 0, 'cuda')\n",
        "    model.train(trainset, validset, 5, 32, 'cuda', 0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YViLocnagxj",
        "outputId": "da6367c6-7525-47e9-d561-4a12b22652c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[valid] mean Loss = 1.114844 | mean accurracy = 0.784624\n",
            "Train Loss: 1.4324\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.844253 | mean accurracy = 0.787345\n",
            "Train Loss: 0.8638\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.683321 | mean accurracy = 0.816481\n",
            "Train Loss: 0.6684\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.581171 | mean accurracy = 0.825110\n",
            "Train Loss: 0.5420\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.523278 | mean accurracy = 0.830003\n",
            "Train Loss: 0.4490\n",
            "--- END OF EPOCH 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO-d3KVc3kTn"
      },
      "source": [
        "The main program is the following. You are expected to add code for searching for hyperparameters that maximise the validation score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Pbx4nEWCX0zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "param_grid = {\n",
        "        'embedding_size': [32, 64, 128],\n",
        "        'hidden_size': [64, 128, 256],\n",
        "        'learning_rate': [0.0005, 0.005, 0.05],\n",
        "        'epochs': [10], # we set it at 10 to keep it from being too long\n",
        "        'batch_size': [32, 64, 128]\n",
        "}\n",
        "\n",
        "best_hyperparameters = None\n",
        "best_loss = 10000000\n",
        "\n",
        "hyperparameter_combinations = product(*param_grid.values())\n",
        "\n",
        "for params in hyperparameter_combinations:\n",
        "    embedding_size, hidden_size, learning_rate, epochs, batch_size = params\n",
        "    print(f\"embedding_size = {embedding_size}, hidden_size = {hidden_size}, learning_rate = {learning_rate}, epochs = {epochs}, batch_size = {batch_size}\")\n",
        "\n",
        "    model = NERtagger(trainset, embedding_size, hidden_size, 'cuda')\n",
        "    model.train(trainset, validset, epochs, batch_size, 'cuda', learning_rate)\n",
        "\n",
        "    if model.minloss < best_loss:\n",
        "        best_loss = model.minloss\n",
        "        best_hyperparameters = {\n",
        "            'embedding_size': embedding_size,\n",
        "            'hidden_size': hidden_size,\n",
        "            'learning_rate': learning_rate,\n",
        "            'epochs': epochs,\n",
        "            'batch_size': batch_size\n",
        "        }\n",
        "\n",
        "    # simplement pour sauvegarder les résultats au cas où\n",
        "    with open('hyperparameter_results.csv', 'a+') as f:\n",
        "        f.write(str(embedding_size) + \",\" + str(hidden_size) + \",\" + str(learning_rate) + \",\" + str(epochs) + \",\" + str(batch_size) + \",\" + str(model.minloss) + \"\\n\")\n",
        "\n",
        "print(\"Best Hyperparameters:\", best_hyperparameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI3WsiEVKDkW",
        "outputId": "07a2e4c2-8186-4973-ad91-15c36267d0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.0005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.796054 | mean accurracy = 0.793534\n",
            "Train Loss: 0.9844\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.526015 | mean accurracy = 0.841266\n",
            "Train Loss: 0.5553\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.394619 | mean accurracy = 0.875046\n",
            "Train Loss: 0.3699\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.325545 | mean accurracy = 0.892210\n",
            "Train Loss: 0.2628\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.292867 | mean accurracy = 0.897580\n",
            "Train Loss: 0.1881\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.249898 | mean accurracy = 0.913481\n",
            "Train Loss: 0.1315\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.231388 | mean accurracy = 0.920636\n",
            "Train Loss: 0.0906\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.234025 | mean accurracy = 0.923483\n",
            "Train Loss: 0.0611\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.242111 | mean accurracy = 0.925732\n",
            "Train Loss: 0.0396\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.266261 | mean accurracy = 0.922835\n",
            "Train Loss: 0.0253\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.0005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.899986 | mean accurracy = 0.786503\n",
            "Train Loss: 1.1917\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.547673 | mean accurracy = 0.833907\n",
            "Train Loss: 0.6115\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.396455 | mean accurracy = 0.875261\n",
            "Train Loss: 0.3834\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.315477 | mean accurracy = 0.898628\n",
            "Train Loss: 0.2693\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.279845 | mean accurracy = 0.904908\n",
            "Train Loss: 0.1924\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.266930 | mean accurracy = 0.906032\n",
            "Train Loss: 0.1344\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.259314 | mean accurracy = 0.910989\n",
            "Train Loss: 0.0937\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.265933 | mean accurracy = 0.914154\n",
            "Train Loss: 0.0631\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.261070 | mean accurracy = 0.921083\n",
            "Train Loss: 0.0412\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.268446 | mean accurracy = 0.925300\n",
            "Train Loss: 0.0258\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.0005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.991147 | mean accurracy = 0.784873\n",
            "Train Loss: 1.4198\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.588406 | mean accurracy = 0.819979\n",
            "Train Loss: 0.6500\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.433794 | mean accurracy = 0.862409\n",
            "Train Loss: 0.4118\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.349813 | mean accurracy = 0.886778\n",
            "Train Loss: 0.2781\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.303627 | mean accurracy = 0.902299\n",
            "Train Loss: 0.1944\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.269754 | mean accurracy = 0.914887\n",
            "Train Loss: 0.1333\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.252115 | mean accurracy = 0.922950\n",
            "Train Loss: 0.0913\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.247066 | mean accurracy = 0.927533\n",
            "Train Loss: 0.0603\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.250051 | mean accurracy = 0.930845\n",
            "Train Loss: 0.0387\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.271669 | mean accurracy = 0.926025\n",
            "Train Loss: 0.0241\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.379027 | mean accurracy = 0.875877\n",
            "Train Loss: 0.5202\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.224223 | mean accurracy = 0.931375\n",
            "Train Loss: 0.1842\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.202278 | mean accurracy = 0.939854\n",
            "Train Loss: 0.0803\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.191689 | mean accurracy = 0.940989\n",
            "Train Loss: 0.0485\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.198575 | mean accurracy = 0.945599\n",
            "Train Loss: 0.0418\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.191665 | mean accurracy = 0.944731\n",
            "Train Loss: 0.0358\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.198135 | mean accurracy = 0.948349\n",
            "Train Loss: 0.0285\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.198261 | mean accurracy = 0.952486\n",
            "Train Loss: 0.0239\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.232728 | mean accurracy = 0.949437\n",
            "Train Loss: 0.0208\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.244881 | mean accurracy = 0.952871\n",
            "Train Loss: 0.0185\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.447297 | mean accurracy = 0.851131\n",
            "Train Loss: 0.6689\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.236318 | mean accurracy = 0.928257\n",
            "Train Loss: 0.2291\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.191380 | mean accurracy = 0.948268\n",
            "Train Loss: 0.0989\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.272921 | mean accurracy = 0.944977\n",
            "Train Loss: 0.0546\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.275010 | mean accurracy = 0.937188\n",
            "Train Loss: 0.0426\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.270464 | mean accurracy = 0.936060\n",
            "Train Loss: 0.0339\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.283214 | mean accurracy = 0.943651\n",
            "Train Loss: 0.0263\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.288179 | mean accurracy = 0.943291\n",
            "Train Loss: 0.0224\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.299891 | mean accurracy = 0.946639\n",
            "Train Loss: 0.0175\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.302958 | mean accurracy = 0.944104\n",
            "Train Loss: 0.0154\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.566455 | mean accurracy = 0.821948\n",
            "Train Loss: 0.8738\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.259603 | mean accurracy = 0.915430\n",
            "Train Loss: 0.2682\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.195569 | mean accurracy = 0.939717\n",
            "Train Loss: 0.1103\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.182296 | mean accurracy = 0.946782\n",
            "Train Loss: 0.0554\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.229510 | mean accurracy = 0.935000\n",
            "Train Loss: 0.0442\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.210753 | mean accurracy = 0.943127\n",
            "Train Loss: 0.0335\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.220085 | mean accurracy = 0.946939\n",
            "Train Loss: 0.0278\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.278787 | mean accurracy = 0.946320\n",
            "Train Loss: 0.0216\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.271384 | mean accurracy = 0.939095\n",
            "Train Loss: 0.0195\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.287775 | mean accurracy = 0.938428\n",
            "Train Loss: 0.0167\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.05, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.338605 | mean accurracy = 0.877648\n",
            "Train Loss: 0.3330\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.432820 | mean accurracy = 0.851284\n",
            "Train Loss: 0.2968\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.483733 | mean accurracy = 0.835247\n",
            "Train Loss: 0.3863\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.505311 | mean accurracy = 0.838021\n",
            "Train Loss: 0.5138\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.606122 | mean accurracy = 0.811915\n",
            "Train Loss: 0.6573\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.680625 | mean accurracy = 0.801865\n",
            "Train Loss: 0.6649\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.650198 | mean accurracy = 0.808516\n",
            "Train Loss: 0.6483\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.619679 | mean accurracy = 0.822923\n",
            "Train Loss: 0.6448\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.643204 | mean accurracy = 0.818257\n",
            "Train Loss: 0.6427\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.655412 | mean accurracy = 0.798395\n",
            "Train Loss: 0.6549\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.05, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.335258 | mean accurracy = 0.889266\n",
            "Train Loss: 0.3834\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.361841 | mean accurracy = 0.888360\n",
            "Train Loss: 0.2767\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.435100 | mean accurracy = 0.859104\n",
            "Train Loss: 0.3717\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.624920 | mean accurracy = 0.826328\n",
            "Train Loss: 0.5134\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.645687 | mean accurracy = 0.825742\n",
            "Train Loss: 0.6741\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.714219 | mean accurracy = 0.797840\n",
            "Train Loss: 0.6935\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.684173 | mean accurracy = 0.804870\n",
            "Train Loss: 0.7023\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.664558 | mean accurracy = 0.817219\n",
            "Train Loss: 0.6923\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.766665 | mean accurracy = 0.797352\n",
            "Train Loss: 0.6957\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.730657 | mean accurracy = 0.806822\n",
            "Train Loss: 0.6919\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 64, learning_rate = 0.05, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.475797 | mean accurracy = 0.852628\n",
            "Train Loss: 0.5207\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.552289 | mean accurracy = 0.842115\n",
            "Train Loss: 0.2464\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.597618 | mean accurracy = 0.829314\n",
            "Train Loss: 0.3531\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.577880 | mean accurracy = 0.815535\n",
            "Train Loss: 0.4897\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.783869 | mean accurracy = 0.788936\n",
            "Train Loss: 0.6269\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.809530 | mean accurracy = 0.792703\n",
            "Train Loss: 0.6475\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.589033 | mean accurracy = 0.815388\n",
            "Train Loss: 0.6556\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.642444 | mean accurracy = 0.797556\n",
            "Train Loss: 0.6609\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.656596 | mean accurracy = 0.810816\n",
            "Train Loss: 0.6457\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.692798 | mean accurracy = 0.805985\n",
            "Train Loss: 0.6470\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.0005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.724419 | mean accurracy = 0.809742\n",
            "Train Loss: 0.8958\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.527014 | mean accurracy = 0.839621\n",
            "Train Loss: 0.4956\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.427680 | mean accurracy = 0.869563\n",
            "Train Loss: 0.3420\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.357448 | mean accurracy = 0.893361\n",
            "Train Loss: 0.2432\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.311395 | mean accurracy = 0.910692\n",
            "Train Loss: 0.1690\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.286176 | mean accurracy = 0.922715\n",
            "Train Loss: 0.1092\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.285324 | mean accurracy = 0.929750\n",
            "Train Loss: 0.0672\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.315012 | mean accurracy = 0.932436\n",
            "Train Loss: 0.0387\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.346972 | mean accurracy = 0.933983\n",
            "Train Loss: 0.0212\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.408950 | mean accurracy = 0.935585\n",
            "Train Loss: 0.0120\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.0005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.883914 | mean accurracy = 0.782944\n",
            "Train Loss: 1.0793\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.550193 | mean accurracy = 0.831932\n",
            "Train Loss: 0.5589\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.439370 | mean accurracy = 0.872602\n",
            "Train Loss: 0.3548\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.359632 | mean accurracy = 0.899087\n",
            "Train Loss: 0.2451\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.318125 | mean accurracy = 0.915419\n",
            "Train Loss: 0.1678\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.298633 | mean accurracy = 0.923401\n",
            "Train Loss: 0.1065\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.299424 | mean accurracy = 0.929096\n",
            "Train Loss: 0.0633\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.310662 | mean accurracy = 0.932364\n",
            "Train Loss: 0.0355\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.341648 | mean accurracy = 0.935348\n",
            "Train Loss: 0.0192\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.371384 | mean accurracy = 0.936688\n",
            "Train Loss: 0.0112\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.0005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.984608 | mean accurracy = 0.785344\n",
            "Train Loss: 1.2667\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.541930 | mean accurracy = 0.834524\n",
            "Train Loss: 0.6047\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.389342 | mean accurracy = 0.871344\n",
            "Train Loss: 0.3734\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.292287 | mean accurracy = 0.903428\n",
            "Train Loss: 0.2561\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.245239 | mean accurracy = 0.917040\n",
            "Train Loss: 0.1756\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.216642 | mean accurracy = 0.928037\n",
            "Train Loss: 0.1112\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.204766 | mean accurracy = 0.932422\n",
            "Train Loss: 0.0670\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.205021 | mean accurracy = 0.936589\n",
            "Train Loss: 0.0381\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.211655 | mean accurracy = 0.940914\n",
            "Train Loss: 0.0208\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.223756 | mean accurracy = 0.943114\n",
            "Train Loss: 0.0116\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.392134 | mean accurracy = 0.872173\n",
            "Train Loss: 0.4972\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.237554 | mean accurracy = 0.924209\n",
            "Train Loss: 0.1836\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.206079 | mean accurracy = 0.936410\n",
            "Train Loss: 0.0810\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.273168 | mean accurracy = 0.916854\n",
            "Train Loss: 0.0525\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.258761 | mean accurracy = 0.921126\n",
            "Train Loss: 0.0484\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.300156 | mean accurracy = 0.915505\n",
            "Train Loss: 0.0390\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.295536 | mean accurracy = 0.919960\n",
            "Train Loss: 0.0343\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.361946 | mean accurracy = 0.911185\n",
            "Train Loss: 0.0321\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.369863 | mean accurracy = 0.913089\n",
            "Train Loss: 0.0297\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.406205 | mean accurracy = 0.905156\n",
            "Train Loss: 0.0286\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.442997 | mean accurracy = 0.853139\n",
            "Train Loss: 0.6388\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.243484 | mean accurracy = 0.917031\n",
            "Train Loss: 0.2289\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.240872 | mean accurracy = 0.919193\n",
            "Train Loss: 0.0990\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.319309 | mean accurracy = 0.908284\n",
            "Train Loss: 0.0570\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.382370 | mean accurracy = 0.900571\n",
            "Train Loss: 0.0507\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.386344 | mean accurracy = 0.911635\n",
            "Train Loss: 0.0404\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.309596 | mean accurracy = 0.914076\n",
            "Train Loss: 0.0343\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.418266 | mean accurracy = 0.904470\n",
            "Train Loss: 0.0278\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.426298 | mean accurracy = 0.911940\n",
            "Train Loss: 0.0265\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.460097 | mean accurracy = 0.906371\n",
            "Train Loss: 0.0243\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.571501 | mean accurracy = 0.821485\n",
            "Train Loss: 0.8219\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.308413 | mean accurracy = 0.890772\n",
            "Train Loss: 0.2639\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.342401 | mean accurracy = 0.902073\n",
            "Train Loss: 0.1149\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.380186 | mean accurracy = 0.899981\n",
            "Train Loss: 0.0629\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.530138 | mean accurracy = 0.892098\n",
            "Train Loss: 0.0528\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.485280 | mean accurracy = 0.897900\n",
            "Train Loss: 0.0438\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.588372 | mean accurracy = 0.898960\n",
            "Train Loss: 0.0370\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.762192 | mean accurracy = 0.901388\n",
            "Train Loss: 0.0297\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.644797 | mean accurracy = 0.901319\n",
            "Train Loss: 0.0272\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.507060 | mean accurracy = 0.901710\n",
            "Train Loss: 0.0256\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.05, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.365743 | mean accurracy = 0.889652\n",
            "Train Loss: 0.3435\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.765774 | mean accurracy = 0.786769\n",
            "Train Loss: 0.5505\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.803835 | mean accurracy = 0.779120\n",
            "Train Loss: 0.9719\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.929864 | mean accurracy = 0.749337\n",
            "Train Loss: 1.2165\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 1.156620 | mean accurracy = 0.735174\n",
            "Train Loss: 1.5659\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 1.059727 | mean accurracy = 0.738268\n",
            "Train Loss: 1.5725\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 1.150191 | mean accurracy = 0.724417\n",
            "Train Loss: 1.5721\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 1.143039 | mean accurracy = 0.727417\n",
            "Train Loss: 1.5429\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 1.051821 | mean accurracy = 0.748944\n",
            "Train Loss: 1.5332\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 1.117751 | mean accurracy = 0.739368\n",
            "Train Loss: 1.5061\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.05, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.307318 | mean accurracy = 0.920883\n",
            "Train Loss: 0.3645\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.720064 | mean accurracy = 0.781660\n",
            "Train Loss: 0.4632\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.770371 | mean accurracy = 0.776418\n",
            "Train Loss: 0.9057\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.946798 | mean accurracy = 0.761873\n",
            "Train Loss: 1.1918\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 1.099337 | mean accurracy = 0.726314\n",
            "Train Loss: 1.5403\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 1.083736 | mean accurracy = 0.739184\n",
            "Train Loss: 1.5524\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 1.026656 | mean accurracy = 0.731959\n",
            "Train Loss: 1.5516\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 1.140886 | mean accurracy = 0.709240\n",
            "Train Loss: 1.5279\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 1.062760 | mean accurracy = 0.724465\n",
            "Train Loss: 1.5296\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 1.072710 | mean accurracy = 0.742042\n",
            "Train Loss: 1.5039\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 128, learning_rate = 0.05, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.291097 | mean accurracy = 0.907299\n",
            "Train Loss: 0.4640\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.755735 | mean accurracy = 0.792144\n",
            "Train Loss: 0.4159\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.797244 | mean accurracy = 0.789624\n",
            "Train Loss: 0.8856\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.920130 | mean accurracy = 0.759794\n",
            "Train Loss: 1.1750\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 1.096552 | mean accurracy = 0.746567\n",
            "Train Loss: 1.5141\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 1.069252 | mean accurracy = 0.729949\n",
            "Train Loss: 1.5398\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 1.080261 | mean accurracy = 0.748734\n",
            "Train Loss: 1.5513\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 1.119194 | mean accurracy = 0.750995\n",
            "Train Loss: 1.5172\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 1.101240 | mean accurracy = 0.757294\n",
            "Train Loss: 1.5080\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 1.061761 | mean accurracy = 0.765143\n",
            "Train Loss: 1.4959\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.0005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.681913 | mean accurracy = 0.816740\n",
            "Train Loss: 0.8278\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.487342 | mean accurracy = 0.846025\n",
            "Train Loss: 0.4693\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.376561 | mean accurracy = 0.880506\n",
            "Train Loss: 0.3213\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.300906 | mean accurracy = 0.905020\n",
            "Train Loss: 0.2241\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.269561 | mean accurracy = 0.917543\n",
            "Train Loss: 0.1498\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.259317 | mean accurracy = 0.926134\n",
            "Train Loss: 0.0862\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.270045 | mean accurracy = 0.930816\n",
            "Train Loss: 0.0450\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.306935 | mean accurracy = 0.932415\n",
            "Train Loss: 0.0215\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.332182 | mean accurracy = 0.936549\n",
            "Train Loss: 0.0109\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.355090 | mean accurracy = 0.938494\n",
            "Train Loss: 0.0076\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.0005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.905377 | mean accurracy = 0.805470\n",
            "Train Loss: 0.9915\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.511396 | mean accurracy = 0.844826\n",
            "Train Loss: 0.5147\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.395116 | mean accurracy = 0.868912\n",
            "Train Loss: 0.3404\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.314652 | mean accurracy = 0.892859\n",
            "Train Loss: 0.2369\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.286375 | mean accurracy = 0.899750\n",
            "Train Loss: 0.1593\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.283700 | mean accurracy = 0.905846\n",
            "Train Loss: 0.0925\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.309616 | mean accurracy = 0.907847\n",
            "Train Loss: 0.0471\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.337314 | mean accurracy = 0.914402\n",
            "Train Loss: 0.0220\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.371088 | mean accurracy = 0.917111\n",
            "Train Loss: 0.0124\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.384911 | mean accurracy = 0.922465\n",
            "Train Loss: 0.0079\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.0005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.960604 | mean accurracy = 0.784791\n",
            "Train Loss: 1.1482\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.532472 | mean accurracy = 0.833622\n",
            "Train Loss: 0.5508\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.413362 | mean accurracy = 0.860129\n",
            "Train Loss: 0.3496\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.320003 | mean accurracy = 0.894970\n",
            "Train Loss: 0.2388\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.276998 | mean accurracy = 0.911164\n",
            "Train Loss: 0.1597\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.291105 | mean accurracy = 0.916551\n",
            "Train Loss: 0.0929\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.268351 | mean accurracy = 0.925912\n",
            "Train Loss: 0.0492\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.318406 | mean accurracy = 0.921743\n",
            "Train Loss: 0.0243\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.333675 | mean accurracy = 0.926391\n",
            "Train Loss: 0.0130\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.314378 | mean accurracy = 0.934028\n",
            "Train Loss: 0.0084\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.378215 | mean accurracy = 0.873482\n",
            "Train Loss: 0.4631\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.214437 | mean accurracy = 0.930067\n",
            "Train Loss: 0.1810\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.190044 | mean accurracy = 0.940820\n",
            "Train Loss: 0.0863\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.225303 | mean accurracy = 0.940783\n",
            "Train Loss: 0.0589\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.258760 | mean accurracy = 0.922477\n",
            "Train Loss: 0.0560\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.329812 | mean accurracy = 0.907003\n",
            "Train Loss: 0.0482\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.403456 | mean accurracy = 0.905687\n",
            "Train Loss: 0.0409\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.367406 | mean accurracy = 0.921625\n",
            "Train Loss: 0.0408\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.463445 | mean accurracy = 0.914081\n",
            "Train Loss: 0.0407\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.344593 | mean accurracy = 0.925288\n",
            "Train Loss: 0.0438\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.490697 | mean accurracy = 0.825768\n",
            "Train Loss: 0.6002\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.309705 | mean accurracy = 0.895671\n",
            "Train Loss: 0.2204\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.326125 | mean accurracy = 0.906183\n",
            "Train Loss: 0.1061\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.414032 | mean accurracy = 0.900005\n",
            "Train Loss: 0.0661\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.609166 | mean accurracy = 0.889078\n",
            "Train Loss: 0.0614\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.633553 | mean accurracy = 0.892528\n",
            "Train Loss: 0.0506\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.835428 | mean accurracy = 0.893746\n",
            "Train Loss: 0.0435\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.863529 | mean accurracy = 0.895277\n",
            "Train Loss: 0.0420\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.788538 | mean accurracy = 0.897865\n",
            "Train Loss: 0.0401\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.988047 | mean accurracy = 0.892406\n",
            "Train Loss: 0.0375\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.568873 | mean accurracy = 0.801054\n",
            "Train Loss: 0.7374\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.285781 | mean accurracy = 0.907338\n",
            "Train Loss: 0.2565\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.226167 | mean accurracy = 0.931192\n",
            "Train Loss: 0.1206\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.245617 | mean accurracy = 0.931014\n",
            "Train Loss: 0.0690\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.308602 | mean accurracy = 0.911843\n",
            "Train Loss: 0.0604\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.321808 | mean accurracy = 0.909743\n",
            "Train Loss: 0.0517\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.437989 | mean accurracy = 0.916605\n",
            "Train Loss: 0.0454\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.494001 | mean accurracy = 0.895960\n",
            "Train Loss: 0.0436\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.483275 | mean accurracy = 0.902301\n",
            "Train Loss: 0.0439\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.459521 | mean accurracy = 0.901615\n",
            "Train Loss: 0.0453\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.05, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.858465 | mean accurracy = 0.772834\n",
            "Train Loss: 0.4659\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.885729 | mean accurracy = 0.782110\n",
            "Train Loss: 1.2729\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.981575 | mean accurracy = 0.778258\n",
            "Train Loss: 1.5716\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 1.237340 | mean accurracy = 0.746859\n",
            "Train Loss: 2.2434\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 1.738390 | mean accurracy = 0.689190\n",
            "Train Loss: 2.9341\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 1.760885 | mean accurracy = 0.718502\n",
            "Train Loss: 2.9914\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 1.732757 | mean accurracy = 0.713796\n",
            "Train Loss: 2.9664\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 1.816984 | mean accurracy = 0.711139\n",
            "Train Loss: 2.9145\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 1.731345 | mean accurracy = 0.704079\n",
            "Train Loss: 3.0063\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 1.766859 | mean accurracy = 0.687552\n",
            "Train Loss: 2.9611\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.05, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.292294 | mean accurracy = 0.898988\n",
            "Train Loss: 0.3789\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.911255 | mean accurracy = 0.756341\n",
            "Train Loss: 0.8980\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.974329 | mean accurracy = 0.759356\n",
            "Train Loss: 1.6934\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 1.336897 | mean accurracy = 0.727647\n",
            "Train Loss: 2.2962\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 1.888473 | mean accurracy = 0.665554\n",
            "Train Loss: 2.9832\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 1.876750 | mean accurracy = 0.655310\n",
            "Train Loss: 2.9780\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 1.827662 | mean accurracy = 0.685117\n",
            "Train Loss: 2.9904\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 1.960553 | mean accurracy = 0.683107\n",
            "Train Loss: 3.0052\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 1.842062 | mean accurracy = 0.685159\n",
            "Train Loss: 3.0080\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 1.840016 | mean accurracy = 0.677255\n",
            "Train Loss: 2.9802\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 32, hidden_size = 256, learning_rate = 0.05, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.329074 | mean accurracy = 0.884897\n",
            "Train Loss: 0.5147\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.873022 | mean accurracy = 0.770786\n",
            "Train Loss: 0.7068\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.936137 | mean accurracy = 0.770119\n",
            "Train Loss: 1.6741\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 1.330101 | mean accurracy = 0.748655\n",
            "Train Loss: 2.1889\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 1.846282 | mean accurracy = 0.699615\n",
            "Train Loss: 2.9107\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 1.759210 | mean accurracy = 0.727710\n",
            "Train Loss: 2.8793\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 1.698997 | mean accurracy = 0.726319\n",
            "Train Loss: 2.9193\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 1.832531 | mean accurracy = 0.729035\n",
            "Train Loss: 2.9113\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 1.877849 | mean accurracy = 0.706419\n",
            "Train Loss: 2.9579\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 1.919545 | mean accurracy = 0.703100\n",
            "Train Loss: 2.9605\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.0005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.709893 | mean accurracy = 0.810985\n",
            "Train Loss: 0.9647\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.456095 | mean accurracy = 0.861315\n",
            "Train Loss: 0.4790\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.347609 | mean accurracy = 0.885556\n",
            "Train Loss: 0.2917\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.291792 | mean accurracy = 0.897479\n",
            "Train Loss: 0.1885\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.275879 | mean accurracy = 0.903080\n",
            "Train Loss: 0.1198\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.259192 | mean accurracy = 0.912598\n",
            "Train Loss: 0.0698\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.266989 | mean accurracy = 0.917099\n",
            "Train Loss: 0.0387\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.277294 | mean accurracy = 0.919140\n",
            "Train Loss: 0.0209\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.292927 | mean accurracy = 0.923712\n",
            "Train Loss: 0.0113\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.297350 | mean accurracy = 0.926454\n",
            "Train Loss: 0.0068\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.0005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.859762 | mean accurracy = 0.784753\n",
            "Train Loss: 1.1582\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.478424 | mean accurracy = 0.852193\n",
            "Train Loss: 0.5479\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.323071 | mean accurracy = 0.899564\n",
            "Train Loss: 0.3104\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.237155 | mean accurracy = 0.923503\n",
            "Train Loss: 0.1959\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.193077 | mean accurracy = 0.937084\n",
            "Train Loss: 0.1230\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.174678 | mean accurracy = 0.943742\n",
            "Train Loss: 0.0697\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.173991 | mean accurracy = 0.948426\n",
            "Train Loss: 0.0375\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.185274 | mean accurracy = 0.949786\n",
            "Train Loss: 0.0199\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.202405 | mean accurracy = 0.951946\n",
            "Train Loss: 0.0107\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.197138 | mean accurracy = 0.953225\n",
            "Train Loss: 0.0061\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.0005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.963771 | mean accurracy = 0.783711\n",
            "Train Loss: 1.4889\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.503118 | mean accurracy = 0.858118\n",
            "Train Loss: 0.5790\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.343756 | mean accurracy = 0.891546\n",
            "Train Loss: 0.3176\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.271660 | mean accurracy = 0.909984\n",
            "Train Loss: 0.1982\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.234897 | mean accurracy = 0.921369\n",
            "Train Loss: 0.1241\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.221198 | mean accurracy = 0.926316\n",
            "Train Loss: 0.0713\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.219496 | mean accurracy = 0.931058\n",
            "Train Loss: 0.0388\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.217930 | mean accurracy = 0.937234\n",
            "Train Loss: 0.0207\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.212880 | mean accurracy = 0.944159\n",
            "Train Loss: 0.0115\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.224184 | mean accurracy = 0.945640\n",
            "Train Loss: 0.0065\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.259681 | mean accurracy = 0.917167\n",
            "Train Loss: 0.4361\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.182169 | mean accurracy = 0.946809\n",
            "Train Loss: 0.1443\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.183033 | mean accurracy = 0.949548\n",
            "Train Loss: 0.0566\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.193493 | mean accurracy = 0.949703\n",
            "Train Loss: 0.0438\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.241542 | mean accurracy = 0.930206\n",
            "Train Loss: 0.0403\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.225534 | mean accurracy = 0.947719\n",
            "Train Loss: 0.0323\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.255895 | mean accurracy = 0.933726\n",
            "Train Loss: 0.0266\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.321207 | mean accurracy = 0.921669\n",
            "Train Loss: 0.0219\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.250310 | mean accurracy = 0.944317\n",
            "Train Loss: 0.0186\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.240158 | mean accurracy = 0.945539\n",
            "Train Loss: 0.0162\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.414702 | mean accurracy = 0.858054\n",
            "Train Loss: 0.5798\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.260001 | mean accurracy = 0.907207\n",
            "Train Loss: 0.1762\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.254378 | mean accurracy = 0.912226\n",
            "Train Loss: 0.0670\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.379436 | mean accurracy = 0.893362\n",
            "Train Loss: 0.0425\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.477007 | mean accurracy = 0.893932\n",
            "Train Loss: 0.0390\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.440583 | mean accurracy = 0.898646\n",
            "Train Loss: 0.0305\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.392438 | mean accurracy = 0.903869\n",
            "Train Loss: 0.0247\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.531450 | mean accurracy = 0.906481\n",
            "Train Loss: 0.0200\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.678010 | mean accurracy = 0.903394\n",
            "Train Loss: 0.0168\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.672127 | mean accurracy = 0.902105\n",
            "Train Loss: 0.0153\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.506727 | mean accurracy = 0.839232\n",
            "Train Loss: 0.8134\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.290338 | mean accurracy = 0.898912\n",
            "Train Loss: 0.2174\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.261971 | mean accurracy = 0.909896\n",
            "Train Loss: 0.0814\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.373240 | mean accurracy = 0.901953\n",
            "Train Loss: 0.0448\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.482770 | mean accurracy = 0.898002\n",
            "Train Loss: 0.0383\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.410170 | mean accurracy = 0.906590\n",
            "Train Loss: 0.0299\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.327875 | mean accurracy = 0.913977\n",
            "Train Loss: 0.0229\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.336730 | mean accurracy = 0.916499\n",
            "Train Loss: 0.0190\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.290838 | mean accurracy = 0.928463\n",
            "Train Loss: 0.0178\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.468454 | mean accurracy = 0.913921\n",
            "Train Loss: 0.0148\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.05, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.352508 | mean accurracy = 0.838669\n",
            "Train Loss: 0.3322\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.421721 | mean accurracy = 0.858695\n",
            "Train Loss: 0.3299\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.403999 | mean accurracy = 0.876448\n",
            "Train Loss: 0.4246\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.586910 | mean accurracy = 0.846952\n",
            "Train Loss: 0.5797\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.678645 | mean accurracy = 0.806534\n",
            "Train Loss: 0.7236\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.611986 | mean accurracy = 0.816647\n",
            "Train Loss: 0.7255\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.620969 | mean accurracy = 0.804335\n",
            "Train Loss: 0.7366\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.677300 | mean accurracy = 0.802712\n",
            "Train Loss: 0.7092\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.664511 | mean accurracy = 0.814452\n",
            "Train Loss: 0.6952\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.687568 | mean accurracy = 0.835911\n",
            "Train Loss: 0.6723\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.05, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.251276 | mean accurracy = 0.914364\n",
            "Train Loss: 0.3648\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.370193 | mean accurracy = 0.886275\n",
            "Train Loss: 0.2976\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.448656 | mean accurracy = 0.855138\n",
            "Train Loss: 0.4168\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.532822 | mean accurracy = 0.831044\n",
            "Train Loss: 0.5529\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.669052 | mean accurracy = 0.809774\n",
            "Train Loss: 0.7035\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.611826 | mean accurracy = 0.820589\n",
            "Train Loss: 0.7048\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.675796 | mean accurracy = 0.832481\n",
            "Train Loss: 0.6939\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.602394 | mean accurracy = 0.827997\n",
            "Train Loss: 0.6961\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.569621 | mean accurracy = 0.833611\n",
            "Train Loss: 0.6833\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.619673 | mean accurracy = 0.838500\n",
            "Train Loss: 0.6641\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 64, learning_rate = 0.05, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.311691 | mean accurracy = 0.899023\n",
            "Train Loss: 0.4642\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.440140 | mean accurracy = 0.857410\n",
            "Train Loss: 0.2792\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.412172 | mean accurracy = 0.875577\n",
            "Train Loss: 0.4102\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.497154 | mean accurracy = 0.850468\n",
            "Train Loss: 0.5707\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.622333 | mean accurracy = 0.821468\n",
            "Train Loss: 0.6978\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.612895 | mean accurracy = 0.823145\n",
            "Train Loss: 0.7025\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.604247 | mean accurracy = 0.829995\n",
            "Train Loss: 0.7065\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.602922 | mean accurracy = 0.827894\n",
            "Train Loss: 0.7049\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.631851 | mean accurracy = 0.827231\n",
            "Train Loss: 0.6986\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.588540 | mean accurracy = 0.827503\n",
            "Train Loss: 0.6804\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 128, learning_rate = 0.0005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.619367 | mean accurracy = 0.825064\n",
            "Train Loss: 0.8505\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.407620 | mean accurracy = 0.870620\n",
            "Train Loss: 0.4173\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.298075 | mean accurracy = 0.901782\n",
            "Train Loss: 0.2537\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.251403 | mean accurracy = 0.915513\n",
            "Train Loss: 0.1593\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.242853 | mean accurracy = 0.913393\n",
            "Train Loss: 0.0929\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.258303 | mean accurracy = 0.912821\n",
            "Train Loss: 0.0454\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.254555 | mean accurracy = 0.924337\n",
            "Train Loss: 0.0207\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.299501 | mean accurracy = 0.920589\n",
            "Train Loss: 0.0106\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.293530 | mean accurracy = 0.927024\n",
            "Train Loss: 0.0060\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.269474 | mean accurracy = 0.935963\n",
            "Train Loss: 0.0040\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 128, learning_rate = 0.0005, epochs = 10, batch_size = 64\n",
            "[valid] mean Loss = 0.788755 | mean accurracy = 0.802662\n",
            "Train Loss: 1.0565\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.428541 | mean accurracy = 0.870772\n",
            "Train Loss: 0.4791\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.304986 | mean accurracy = 0.904197\n",
            "Train Loss: 0.2821\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.231960 | mean accurracy = 0.928005\n",
            "Train Loss: 0.1770\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.195287 | mean accurracy = 0.941445\n",
            "Train Loss: 0.1043\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.183837 | mean accurracy = 0.946904\n",
            "Train Loss: 0.0522\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.187642 | mean accurracy = 0.947614\n",
            "Train Loss: 0.0240\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.193676 | mean accurracy = 0.951692\n",
            "Train Loss: 0.0108\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.203668 | mean accurracy = 0.952742\n",
            "Train Loss: 0.0063\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.216331 | mean accurracy = 0.955369\n",
            "Train Loss: 0.0043\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 128, learning_rate = 0.0005, epochs = 10, batch_size = 128\n",
            "[valid] mean Loss = 0.932661 | mean accurracy = 0.786482\n",
            "Train Loss: 1.3238\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.467563 | mean accurracy = 0.861792\n",
            "Train Loss: 0.5298\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.322848 | mean accurracy = 0.898621\n",
            "Train Loss: 0.2981\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.245226 | mean accurracy = 0.922224\n",
            "Train Loss: 0.1843\n",
            "--- END OF EPOCH 3\n",
            "[valid] mean Loss = 0.209061 | mean accurracy = 0.934097\n",
            "Train Loss: 0.1067\n",
            "--- END OF EPOCH 4\n",
            "[valid] mean Loss = 0.203678 | mean accurracy = 0.938932\n",
            "Train Loss: 0.0521\n",
            "--- END OF EPOCH 5\n",
            "[valid] mean Loss = 0.210280 | mean accurracy = 0.942633\n",
            "Train Loss: 0.0241\n",
            "--- END OF EPOCH 6\n",
            "[valid] mean Loss = 0.232526 | mean accurracy = 0.941604\n",
            "Train Loss: 0.0116\n",
            "--- END OF EPOCH 7\n",
            "[valid] mean Loss = 0.247665 | mean accurracy = 0.943053\n",
            "Train Loss: 0.0066\n",
            "--- END OF EPOCH 8\n",
            "[valid] mean Loss = 0.263008 | mean accurracy = 0.944937\n",
            "Train Loss: 0.0042\n",
            "--- END OF EPOCH 9\n",
            "embedding_size = 64, hidden_size = 128, learning_rate = 0.005, epochs = 10, batch_size = 32\n",
            "[valid] mean Loss = 0.357260 | mean accurracy = 0.873240\n",
            "Train Loss: 0.4038\n",
            "--- END OF EPOCH 0\n",
            "[valid] mean Loss = 0.345487 | mean accurracy = 0.894518\n",
            "Train Loss: 0.1400\n",
            "--- END OF EPOCH 1\n",
            "[valid] mean Loss = 0.449169 | mean accurracy = 0.899239\n",
            "Train Loss: 0.0596\n",
            "--- END OF EPOCH 2\n",
            "[valid] mean Loss = 0.572259 | mean accurracy = 0.893107\n",
            "Train Loss: 0.0461\n",
            "--- END OF EPOCH 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgTLQvRT5t9L"
      },
      "source": [
        "Fourth exercise : improve the tagger (5pts)\n",
        "----------\n",
        "\n",
        "This exercise is relatively free. You may add improvements to the basic tagger.\n",
        "Note that I expect that improving the management of unknown words and of subword units is key on this task. You may wish to:\n",
        "* Add an attention layer\n",
        "* Use part of speech tags embeddings as additional inputs\n",
        "* Find a way to learn a word embedding for unknown words\n",
        "* Integrate your convolutional word embedding module into the tagger\n",
        "* ...\n",
        "\n",
        "Describe your improvements below and point me out the name(s) of the function(s)\n",
        "where they are implemented.\n"
      ]
    }
  ]
}